{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris의 세 가지 품종, 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [scikit-learn : dataset](https://scikit-learn.org/stable/datasets/index.html)\n",
    "\n",
    "- [iris datasets 링크 ](https://scikit-learn.org/stable/datasets/index.html#iris-plants-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "print(type(dir(iris))) \n",
    "# dir()는 객체가 어떤 변수와 메서드를 가지고 있는지 나열함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iris 에  담긴 정보 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 크기 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "iris_data = iris.data\n",
    "\n",
    "print(iris_data.shape) \n",
    "#shape는 배열의 형상정보를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 150개 데이터 4개의 정보를 담고 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0번 index로 접근해서 확인해 보니, 총 네 개의 숫자가 나옵니다.\n",
    "-  순서대로 sepal length, sepal width, petal length, petal width 를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label 정보 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 꽃잎, 꽃받침의 길이와 폭 정보를 가지고 붓꽃 품종을 출력하도록 학습하려는 것이다. \n",
    "- 모델이 출력해야하는 정답을 라벨(label) 또는 target이라고 합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_label = iris.target\n",
    "\n",
    "print(iris_label.shape)\n",
    "\n",
    "iris_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 길이와 형태를 확인하니 총 150개의 데이터가 들어있고, 각 값은 0, 1, 또는 2로 나타나는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setosa, versicolor, virginica 순서대로 담겨있다.\n",
    "- 0 : setosa, 1 : versicolor, 2 : virginica를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  feature 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data set 저장경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel0042/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/iris.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data frame 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label 추가 (정답)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df[\"label\"] = iris.target\n",
    "\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [\"label\"] 이라는 코드로 라벨 컬럼을 추가했다. \n",
    "- 0~2 사이의 값\n",
    "- [5.1, 3.5, 1.4, 0.2]라는 문제가 주어진다면 모델은 0, 즉 setosa라는 답을 맞추어야 하는 것이다. \n",
    "- 0, 1, 2 라는 label 데이터는 정답지와 같다. \n",
    "\n",
    "#### feature = 문제지, 모델에게 임력되는 데이터 , 변수로는 `x`를 사용 \n",
    "#### label = 정답지, 모델이 맞춰야 하는 데이터 target이라고도 부른다. `y`를 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data / test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  120 , X_test 개수:  30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                   iris_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 번째 파라미터인 iris_data는 문제지, 즉 feature \n",
    "- 모델이 품종을 맞추기 위해 입력받는 특징 데이터 \n",
    "- iris 데이터셋에서는 4가지의 특징 정보가 있다. \n",
    "\n",
    "- 두 번째 파라미터인 iris_label은 모델이 맞추어야 하는 정답값, 즉 label\n",
    "- 총 세 가지 품종이 있다.\n",
    "\n",
    "#### 4개의 feature   `x`  , 1개의 label `y` 를 얻을 수 있다. \n",
    "#### test_size  :  0.2 는 20%를 테스트 데이터로 사용 하겠다. \n",
    "#### random_state : train과 test데이터를 분리하는데 적용하는 램덤성 \n",
    "- 컴퓨터에서의 랜덤은 아무리 랜덤이라고 해도 특정 로직에 따라 결정되는 랜덤이기 때문에 완벽한 랜덤이라고 할 수 없습니다.\n",
    "\n",
    "- 그러한 랜덤을 조절할 수 있는 값이 바로 random_state, 또는 random_seed입니다. 이 값이 같다면 코드는 항상 같은 랜덤 결과를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 4), (30,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train / test  Label\n",
    "-  무작위로 섞여 있는 것을 확인 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 2, 0, 0, 0,\n",
       "        2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0,\n",
       "        1, 2, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 2, 2, 1, 0, 1, 0, 2, 2,\n",
       "        0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 0, 1, 2, 2, 1, 1, 0, 2, 0, 0, 1,\n",
       "        1, 2, 0, 1, 1, 2, 2, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 2,\n",
       "        0, 2, 1, 1, 0, 2, 1, 2, 1, 0]),\n",
       " array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2,\n",
       "        1, 2, 2, 2, 1, 1, 2, 2]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지도학습 (Supervised Learning) :\n",
    "    지도학습은 지도받을 수 있는, 즉 정답이 있는 문제에 대해 학습하는 것\n",
    "- 비지도 학습 (Unsupervised Learning) :\n",
    "    비지도학습은 정답이 없는 문제를 학습하는 것을 말합니다. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지도학습\n",
    "- 분류(Classification) : 입력받은 데이터를 특정 카테고리 중 하나로 분류해내는 문제\n",
    "- 회귀(Regression): 입력받은 데이터에 따라 특정 필드의 수치를 맞추는 문제\n",
    "    - 집에 대한 정보(평수, 위치, 층수 등)를 입력받아 그 집의 가격을 맞추는 문제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "#### [의사 결정 나무](https://ratsgo.github.io/machine%20learning/2017/03/26/tree/)\n",
    "\n",
    "- 의사결정나무는 데이터를 분석하여 이들 사이에 존재하는 패턴을 예측 가능한 규칙들의 조합으로 나타낸다. \n",
    "- 그 모양이 ‘나무’와 같다고 해서 의사결정나무라 불립니다. \n",
    "- 질문을 던져서 대상을 좁혀나가는 ‘스무고개’ 놀이와 비슷한 개념입니다\n",
    "\n",
    "- 분류 / 회귀 모두 가능, 범주형 연속형 모두 예측 할 수 있다. \n",
    "- 새로운 데이터가 특정 terminal node에 속한다는 정보를 확인한 뒤 해당 terminal node에서 가장 빈도가 높은 범주에 새로운 데이터를 분류하게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 나무 순도 계산 \n",
    "분류나무는 각 영역의 순도가 증가 불순도와 불확실성이 최대한으로 감소하는 방향으로 학습을 진행합니다.  이를 정보획득이라고 하는데,  즉 이런 순도를 계산하는 방법에는 엔트로피(entropy) , 지니계수 (Gini index) , 오분류오차 (misclassification error) 등이 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "print(decision_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=32, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가 \n",
    "\n",
    "#### 예측 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 2, 2, 0, 0, 1, 2,\n",
       "       1, 1, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이 완료된 decision_tree 모델에 X_test 데이터로 predict를 실행하면 모델이 예측한 `y_pred`을 얻게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제 정답 label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2,\n",
       "       1, 2, 2, 2, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy (정확도) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 90% 정확도를 보인다. \n",
    "- 정확도는 전체 개수 중 맞은 것의 개수의 수치\n",
    "- test label 30개중 27개가 맞았다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 다른 모델 학습 \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# (2) 데이터 준비\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  RandomForest\n",
    " - Decision Tree 모델을 여러개 합쳐놓음으로써 Decision Tree의 단점을 극복한 모델\n",
    " - 이러한 기법을 앙상블(Ensemble) 기법이라고 합니다. \n",
    " - 단일 모델을 여러 개 사용하는 방법을 취함으로써 모델 한 개만 사용할 때의 단점을 집단지성으로 극복하는 개념\n",
    " - [군중은 똑똑하다 — Random Forest](https://medium.com/@deepvalidation/title-3b0e263605de)\n",
    " \n",
    " - Random Forest는 각각의 의사 결정 트리를 만드는데 있어 쓰이는 요소들)을 무작위적으로 선정합니다. 의사 결정 한 단계를 생성하면서 모든 요소를 고려하지 않고 그 중 일부만 랜덤으로 선택하고 이중 가장 잘 예측하는 요소가  의사 결정 트리의 한 단계입니다.  이런 단계를 원하는 개수의 트리가 생성되고 이 생성된 트리들 중 한가지 의견을 통합해 결과를 내게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       0.88      0.88      0.88         8\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=25)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suport Vector Machine - SVM, 서포트 벡터 머신\n",
    "\n",
    "- Support Vector Machine(SVM)은 원 훈련(또는 학습)데이터를 비선형 매핑(Mapping)을 통해 고차원으로 변환한다. \n",
    "- 이 새로운 차원에서 초평면(hyperplane)을 최적으로 분리하는 선형분리를 찾는다.\n",
    "- 즉, 최적의 Decision Boundary(의사결정 영역)를 찾는다.\n",
    "- SVM은 복잡한 비선형 의사결정 영역을 모형화 할 수 있기 때문에 매우 정확하며, 다른 모델들 보다 Over Fitting되는 경향이 적다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.95      0.94        30\n",
      "weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, \n",
    "                                                    iris_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=25)\n",
    "C = 1.0  # SVM regularization parameter\n",
    "\n",
    "svm = svm.SVC(kernel='linear', C=C)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier (SGDClassifier)\n",
    "- (선형) 서포트 벡터 머신 및 로지스틱 회귀와 같은 볼록 손실 함수 하에서 선형 분류기와 회귀를 맞추는 단순하면서도 매우 효율적인 접근 방식입니다\n",
    "- SGD는 텍스트 분류 및 자연어 처리에서 자주 발생하는 대규모 및 희소 기계 학습 문제에 성공적으로 적용되었습니다. 데이터가 드문 경우이 모듈의 분류기는 10 ~ 5 개 이상의 교육 예제 및 10 ~ 5 개 이상의 기능 관련 문제로 쉽게 확장 할 수 있습니다.\n",
    "-  SGD는 최적화 기술 일 뿐이며 특정 머신 러닝 모델 제품군에 해당하지 않습니다. 모델을 훈련시키는 방법 일뿐입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       0.72      1.00      0.84        13\n",
      "           2       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.91      0.80      0.82        30\n",
      "weighted avg       0.88      0.83      0.82        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)\n",
    "\n",
    "sgd = SGDClassifier(alpha=0.001, max_iter = 1000)\n",
    "sgd.fit(X_train,  y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - 로지스틱 회귀\n",
    "\n",
    "#### [로지스틱회귀(Logistic Regression) 쉽게 이해하기](http://hleecaster.com/ml-logistic-regression-concept/)\n",
    "\n",
    "- 로지스틱 회귀 분석은 이진 분류를 수행하는 데 사용된다. 즉, 데이터 샘플을 양성(1) 또는 음성(0) 클래스 둘 중 어디에 속하는지 예측한다.\n",
    "\n",
    "- 각 속성(feature)들의 계수 log-odds를 구한 후 Sigmoid 함수를 적용하여 실제로 데이터가 해당 클래스에 속할 확률을 0과 1사이의 값으로 나타낸다.\n",
    "- 손실함수(Loss Function)는 머신러닝 모델이 얼마나 잘 예측하는지 확인하는 방법이다. 로지스틱 회귀의 손실함수는 Log Loss이다.\n",
    "- 데이터가 클래스에 속할지 말지 결정할 확률 컷오프를 Threshold(임계값)이라 한다. 기본 값은 0.5이지만 데이터의 특성이나 상황에 따라 조정할 수 있다.\n",
    "- 파이썬 라이브러리 Scikit-learn을 통해 모델을 생성하고 각 속성(feature)들의 계수를 구할 수 있다. 이 때 각 계수(coefficients)들은 데이터를 분류함에 있어 해당 속성이 얼마나 중요한지 해석하는 데에 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "print(logistic_model._estimator_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(multi_class=\"multinomial\", max_iter= 1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  정확도 함정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터 셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "digits_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터는 총 1797개가 있고, 각 데이터는 64개의 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째데이터 샘플 확인\n",
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 손글씨 데이터는 이미지 데이터입니다. 따라서 각 숫자는 픽셀값을 의미하죠. \n",
    "- 길이 64의 숫자 배열은 사실 (8 x 8) 크기의 이미지를 일렬로 쭉 펴놓은 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label 값 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도의 함정을 확인하기 위한 실험\n",
    "\n",
    "- 숫자 10개를 모두 분류하는 것이 아니라, 해당 이미지 데이터가 3인지 아닌지를 맞추는 문제로 변형해서 풀어보는 것입니다.\n",
    "- 즉, 입력된 데이터가 3이라면 3을, 3이 아닌 다른 숫자라면 0을 출력하도록 하는 모델을 생각해 보겠습니다.\n",
    "\n",
    "- 그러려면, 우리는 target인 digits_label을 살짝 변형할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label = [3 if i == 3 else 0 for i in digits_label]\n",
    "new_label[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  digits_data와 new_label로 Decision Tree 모델을 학습시키고, 정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       326\n",
      "           3       0.77      0.88      0.82        34\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.88      0.93      0.90       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                   new_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "# print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리는 총 10개의 숫자 중 3에만 집중을 해서, 3이라면 3으로, 3이 아니라면 0으로 맞추는 문제로 변형했었죠.\n",
    "- 그런 이유로, 정답 데이터인 label은 0이 굉장히 많고 3은 적은 불균형 데이터가 되었습니다.\n",
    "- 9개의 숫자들은 label이 모두 0이 되었고, 3만 3으로 남아있었으니 대략 90%의 label이 모두 0이라는 이야기가 되죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델이 전혀 학습하지 않고 정답을 모두 0으로만 선택해도 정확도가 90%가량이 나오게 된다는 것\n",
    "\n",
    "- 길이는 y_pred와 같으면서 0으로만 이루어진 리스트를 fake_pred 라는 변수로 저장해 보고, 이 리스트와 실제 정답인 y_test간의 정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9055555555555556"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_pred = [0] * len(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, fake_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이러한 문제는 불균형한 데이터, unbalanced 데이터에서 많이 발생할 수 있습니다.\n",
    "\n",
    "- 즉, 정확도는 정답의 분포에 따라 모델의 성능을 잘 평가하지 못하는 척도가 될 수 있는 것이죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차행렬(confusion matrix) \n",
    "\n",
    "- [What is Confusion Matrix and Advanced Classification Metrics?]()\n",
    "\n",
    "![](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)\n",
    "\n",
    "\n",
    "1. **TP, (True Positive)**는 positive 올바르게 식별 된  positive클래스를 의미합니다.\n",
    "    예 : 주어진 클래스가 스팸이고 분류자가 스팸으로 올바르게 예측했습니다.\n",
    "\n",
    "2. **FN (False Negative, FN)**은 positive 클래스가 Negative으로 잘못 식별됨을 의미합니다.\n",
    "    예 : 클래스가 스팸 인 경우 분류자가 스팸이 아닌 것으로 잘못 예측했습니다.\n",
    "\n",
    "3. **FP, False Positive (FP)**는 negative 클래스가 잘못 Positive으로 식별됨을 의미합니다.\n",
    "    예 : 클래스가 스팸이 아닌 경우 분류자가 해당 스팸을 스팸으로 잘못 예측했습니다.\n",
    "\n",
    "4. **TN, (True Negative)**은 negative 클래스가 negative로 올바르게 식별됩니다.\n",
    "    예 : 주어진 클래스가 스팸이고 분류자가 이를 부정으로 올바르게 예측했습니다.\n",
    "    \n",
    "    \n",
    "다음 그림에서 각 행은 실제 클래스(Actual Class)를 나타냅니다.\n",
    "위에서 들었던 코로나의 예시를 계속 생각해 볼 때, Actual Class가 Positive라면 환자는 실제 코로나에 걸린 것이죠.\n",
    "반대로 Actual Class가 Negative라면 환자는 건강합니다.\n",
    "\n",
    "반면 각 열은 예측된 클래스(Predicted Class)입니다.\n",
    "Predicted Class가 Positive라면 진단 결과가 양성, Negative라면 진단 결과가 음성인 것을 말합니다.\n",
    "\n",
    "그래서 각 칸에 나타난 TP, FN, FP, TN은 다음과 같습니다.\n",
    "\n",
    "- TP(True Positive) : 실제 환자에게 양성판정 (참 양성)\n",
    "- FN(False Negative) : 실제 환자에게 음성판정 (거짓 양성)\n",
    "- FP(False Positive) : 건강한 사람에게 양성판정 (거짓 음성)\n",
    "- TN(True Negative) : 건강한 사람에게 음성판정 (참 음성)\n",
    "\n",
    "\n",
    "Precision과 Recall의 분자는 둘 다 TP입니다. TP는 맞게 판단한 양성이므로, 이 값은 높을수록 좋습니다. 하지만 분모에는 각각 FP와 FN가 있습니다. 이 값들은 잘못 판단된 것들이므로 낮을수록 좋습니다. 즉, TP는 높고 FP또는 FN이 낮을수록 좋은 예측이므로, Precision과 Recall 값이 클수록 좋습니다. 다만, 둘은 다음과 같은 점이 다릅니다.\n",
    "\n",
    "- Precision은 분모에 있는 `FP`가 낮을수록 커집니다. Precision이 높아지려면 False Positive, 즉 음성인데 양성으로 판단하는 경우가 적어야 합니다.\n",
    "- Recall은 분모에 있는 `FN`이 낮을수록 커집니다. Recall이 높아지려면 False Negative, 즉 양성인데 음성으로 판단하는 경우가 적어야 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity : 민감도\n",
    "$$\\frac{TP}{(TP+FN)}$$\n",
    "- True Positive Rate , 또는 **Recall** 이라고도 한다. \n",
    "- positive Label을 positive 클래스로 측정한 것이고 , 모든 스팸 이메일 중 스팸 이메일의 비율 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity : 특이도\n",
    "$$ \\frac{TN}{(TN+FP)}$$\n",
    "- True Neagative Rate \n",
    "- negative label을 negative로 분류한 비율 \n",
    "- 높아야 좋다. 예를 들어 스팸이 아닌 이메일 중 스팸 이메일이 아닌 비율 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision : 정밀도\n",
    "$$ \\frac{TP}{(TP+FP)} $$\n",
    "- Positice Predictive Value : Positive 정답률 \n",
    "- 모델이 True 라고 분류한 중에 실제 True의 비율 \n",
    "- spam 을 spam메일로 분류한 비율 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy : 정확도\n",
    "\n",
    "$$\\frac{TP + TN}{(TP+TN+FP+FN)}$$\n",
    "- 정확도는 정확한 총 예측 수의 비율입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score :\n",
    "\n",
    "F1 score는 데이터 label이 불균형 구조일 때, 모델의 성능을 정확하게 평가할 수 있으며, 성능을 하나의 숫자로 표현할 수 있습니다\n",
    "\n",
    "$$ 2 x \\frac{Precision X Recall}{Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[317,   9],\n",
       "       [  4,  30]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  왼쪽 위부터 순서대로 `TP`, `FN`, `FP`, `TN`의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fake _pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[326,   0],\n",
       "       [ 34,   0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, fake_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 네, 우리는 모든 데이터를 0, 즉 Positive로 예측했고 Negative로 예측한 것은 없기 때문에 `FN`과 `TN`은 둘 다 0입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calssification_report \n",
    "\n",
    "- 각 지표를 한번에 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       326\n",
      "           3       0.77      0.88      0.82        34\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.88      0.93      0.90       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fake_pred 의 confusion matrix 결과 \n",
    "\n",
    "이게 무슨 일이죠? 0에 대한 precision과 recall은 0.93, 1로 매우 높지만 3에 대한 precision과 recall은 둘 다 0입니다.\n",
    "이는 큰 문제입니다. 0은 잘 잡아내지만, 3은 단 하나도 맞추지 못했다는 뜻이니까요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       326\n",
      "           3       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.91       360\n",
      "   macro avg       0.45      0.50      0.48       360\n",
      "weighted avg       0.82      0.91      0.86       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, fake_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9638888888888889, 0.9055555555555556)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred), accuracy_score(y_test, fake_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
