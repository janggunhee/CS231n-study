{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니프로젝트 : 가위바위보 분류기 만들기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 준비하기 \n",
    "\n",
    "### 가위 / 바위 / 보 이미지 데이터 만들기 \n",
    "\n",
    "- 구글의 teachable machine 사이트에서 쉽게 데이터를 만들어볼 수 있습니다.\n",
    "\n",
    "- 아래 사이트에서 Get Started 버튼을 눌러보세요.\n",
    "\n",
    "- 그 다음, Image Project를 선택하면 Webcam을 구동해 클래스별 이미지 데이터를 직접 촬영해서 만들 수 있는 멋진 화면이 나타납니다.\n",
    "\n",
    "- [goggle teachable machine 링크](https://teachablemachine.withgoogle.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 + Resize 하기 \n",
    "\n",
    "- 구글로 만들어진 이미지의 사이즈가 224x224 이다. \n",
    "- 그래서 28x28 사이즈로 Resize 해줘야 합니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "# !pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가위 Resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0042/Project/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Project/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바위 Resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0042/Project/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Project/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 보 Resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0042/Project/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Project/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러들어오기 load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 7500 입니다.\n",
      "x_train shape: (7500, 28, 28, 3)\n",
      "y_train shape: (7500,)\n",
      "최소값: 0  최대값: 255\n",
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=7500   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Project/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "# x_train 최소값 0 , 최대값 255 그래서 정규화를 /255.0 으로 해주어 최소값 최대값을 0-1 사이의 값으로 바꿈\n",
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[3])\n",
    "print('라벨: ', y_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 학습시키기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.0058 - accuracy: 0.5016\n",
      "Epoch 2/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.7363 - accuracy: 0.7047\n",
      "Epoch 3/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5753 - accuracy: 0.7852\n",
      "Epoch 4/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.8381\n",
      "Epoch 5/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8837\n",
      "Epoch 6/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.9057\n",
      "Epoch 7/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.9244\n",
      "Epoch 8/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1936 - accuracy: 0.9392\n",
      "Epoch 9/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1644 - accuracy: 0.9497\n",
      "Epoch 10/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.1377 - accuracy: 0.9589\n",
      "Epoch 11/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1187 - accuracy: 0.9639\n",
      "Epoch 12/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1025 - accuracy: 0.9668\n",
      "Epoch 13/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0850 - accuracy: 0.9732\n",
      "Epoch 14/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.9780\n",
      "Epoch 15/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9776\n",
      "Epoch 16/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9815\n",
      "Epoch 17/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0484 - accuracy: 0.9848\n",
      "Epoch 18/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9903\n",
      "Epoch 19/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9936\n",
      "Epoch 20/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9931\n",
      "Epoch 21/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9921\n",
      "Epoch 22/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9953\n",
      "Epoch 23/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9964\n",
      "Epoch 24/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9977\n",
      "Epoch 25/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9983\n",
      "Epoch 26/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0106 - accuracy: 0.9977\n",
      "Epoch 27/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9859\n",
      "Epoch 28/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0146 - accuracy: 0.9964\n",
      "Epoch 29/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9995\n",
      "Epoch 30/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 31/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 32/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 33/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 34/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 9.8137e-04 - accuracy: 1.0000\n",
      "Epoch 35/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 8.2527e-04 - accuracy: 1.0000\n",
      "Epoch 36/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 7.0565e-04 - accuracy: 1.0000\n",
      "Epoch 37/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 6.3608e-04 - accuracy: 1.0000\n",
      "Epoch 38/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 5.3912e-04 - accuracy: 1.0000\n",
      "Epoch 39/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 4.8268e-04 - accuracy: 1.0000\n",
      "Epoch 40/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 4.2990e-04 - accuracy: 1.0000\n",
      "Epoch 41/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 3.7121e-04 - accuracy: 1.0000\n",
      "Epoch 42/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 3.3018e-04 - accuracy: 1.0000\n",
      "Epoch 43/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 3.0160e-04 - accuracy: 1.0000\n",
      "Epoch 44/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 2.4548e-04 - accuracy: 1.0000\n",
      "Epoch 45/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 2.2259e-04 - accuracy: 1.0000\n",
      "Epoch 46/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.9644e-04 - accuracy: 1.0000\n",
      "Epoch 47/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.7118e-04 - accuracy: 1.0000\n",
      "Epoch 48/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.5273e-04 - accuracy: 1.0000\n",
      "Epoch 49/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.2591e-04 - accuracy: 1.0000\n",
      "Epoch 50/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.1852e-04 - accuracy: 1.0000\n",
      "Epoch 51/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 9.7894e-05 - accuracy: 1.0000\n",
      "Epoch 52/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 9.0178e-05 - accuracy: 1.0000\n",
      "Epoch 53/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 8.7893e-05 - accuracy: 1.0000\n",
      "Epoch 54/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 6.9085e-05 - accuracy: 1.0000\n",
      "Epoch 55/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 5.7568e-05 - accuracy: 1.0000\n",
      "Epoch 56/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 4.7990e-05 - accuracy: 1.0000\n",
      "Epoch 57/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 4.1634e-05 - accuracy: 1.0000\n",
      "Epoch 58/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 4.0325e-05 - accuracy: 1.0000\n",
      "Epoch 59/60\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 3.4988e-05 - accuracy: 1.0000\n",
      "Epoch 60/60\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 2.9363e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff39c5350d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 600 입니다.\n",
      "x_test shape: (600, 28, 28, 3)\n",
      "x_test_norm shape: (600, 28, 28, 3)\n",
      "y_test shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Project/test_rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/217.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터로 성능 확인\n",
    "\n",
    "- 학습용 데이터 x_train 을 가지고 구한 정확도 와 y_test 데이터와의 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 0s - loss: 0.7816 - accuracy: 0.9083\n",
      "test_loss: 0.7815627455711365 \n",
      "test_accuracy: 0.9083333611488342\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분석 목표 및 고찰 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MNIST 같이 학습용으로 잘 정제된 데이터셋과 달리 직접 만들어 쓰는 이미지 데이터 셋에 접근하는 방법 \n",
    "2. 흑백과 컬러 이미지의 네트워크 모델링 차이  \n",
    "3. 데이터량의 증가로 개선되는 정확도 \n",
    "\n",
    "---\n",
    "\n",
    "- 총 3백장의 가위, 바위, 보 train 데이터셋으로 학습시 정확도는 100에 가까웠다. \n",
    "- 300장의 test데이터 셋으로 학습정확도를 정검한 결과 31% 정확도를 보였다. \n",
    "- 우선 살펴본 test 데이터 셋과 train 데이터 셋의 이미지 상태는 찍힌 배경과 상황에 따라 시각적으로 판단하기에도 매우 달랐고 특히 배경에 여러 물체가 같이 찍힌 이미지는 분류과정에서 오류나는 경우가 많았다. \n",
    "- 정확도를 개선하기 위해 좀 더 다양한 시점과 배경, 다른 상황에서 찍힌 가위, 바위, 보 데이터 셋을 총 7500장을 모았고 이를 분류한 결과는 90% 넘는 정확도를 보였다. \n",
    "- 단지 데이터셋을 늘렸을 뿐인데 이렇게 다른 결과를 보인 점이 흥미로웠고 데이터셋의 중요도를 인지할 수 있었다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
